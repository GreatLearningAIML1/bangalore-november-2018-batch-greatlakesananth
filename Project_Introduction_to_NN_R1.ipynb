{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber','CustomerId','Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['Geography','Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinguish the feature and target set (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.drop('Exited', axis=1)\n",
    "df_target = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size=0.30, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the train and test data (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "training_normalized = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalized = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.array(y_train)\n",
    "y_te = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train=np_utils.to_categorical(y_train)\n",
    "Y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize & build the model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 0.6138 - acc: 0.7604\n",
      "Epoch 2/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5316 - acc: 0.7926\n",
      "Epoch 3/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5144 - acc: 0.7926\n",
      "Epoch 4/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5113 - acc: 0.7926\n",
      "Epoch 5/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5103 - acc: 0.7926\n",
      "Epoch 6/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5096 - acc: 0.7926\n",
      "Epoch 7/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5090 - acc: 0.7926\n",
      "Epoch 8/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5085 - acc: 0.7926\n",
      "Epoch 9/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5081 - acc: 0.7926\n",
      "Epoch 10/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5077 - acc: 0.7926\n",
      "Epoch 11/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5074 - acc: 0.7926\n",
      "Epoch 12/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5072 - acc: 0.7926\n",
      "Epoch 13/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5069 - acc: 0.7926\n",
      "Epoch 14/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5067 - acc: 0.7926\n",
      "Epoch 15/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5064 - acc: 0.7926\n",
      "Epoch 16/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5063 - acc: 0.7926\n",
      "Epoch 17/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5061 - acc: 0.7926\n",
      "Epoch 18/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5060 - acc: 0.7926\n",
      "Epoch 19/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5058 - acc: 0.7926\n",
      "Epoch 20/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5057 - acc: 0.7926\n",
      "Epoch 21/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5056 - acc: 0.7926\n",
      "Epoch 22/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5054 - acc: 0.7926\n",
      "Epoch 23/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5053 - acc: 0.7926\n",
      "Epoch 24/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5052 - acc: 0.7926\n",
      "Epoch 25/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5052 - acc: 0.7926\n",
      "Epoch 26/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5051 - acc: 0.7926\n",
      "Epoch 27/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5050 - acc: 0.7926\n",
      "Epoch 28/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5049 - acc: 0.7926\n",
      "Epoch 29/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5049 - acc: 0.7926\n",
      "Epoch 30/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5048 - acc: 0.7926\n",
      "Epoch 31/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5047 - acc: 0.7926\n",
      "Epoch 32/150\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.5047 - acc: 0.7926\n",
      "Epoch 33/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5046 - acc: 0.7926\n",
      "Epoch 34/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5045 - acc: 0.7926\n",
      "Epoch 35/150\n",
      "7000/7000 [==============================] - 0s 38us/step - loss: 0.5045 - acc: 0.7926\n",
      "Epoch 36/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5044 - acc: 0.7926\n",
      "Epoch 37/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5044 - acc: 0.7926\n",
      "Epoch 38/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5043 - acc: 0.7926\n",
      "Epoch 39/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5042 - acc: 0.7926\n",
      "Epoch 40/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5042 - acc: 0.7926\n",
      "Epoch 41/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5041 - acc: 0.7926\n",
      "Epoch 42/150\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.5040 - acc: 0.7926\n",
      "Epoch 43/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5040 - acc: 0.7926\n",
      "Epoch 44/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5040 - acc: 0.7926\n",
      "Epoch 45/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5039 - acc: 0.7926\n",
      "Epoch 46/150\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.5039 - acc: 0.7926\n",
      "Epoch 47/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5038 - acc: 0.7926\n",
      "Epoch 48/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5038 - acc: 0.7926\n",
      "Epoch 49/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5038 - acc: 0.7926\n",
      "Epoch 50/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5037 - acc: 0.7926\n",
      "Epoch 51/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5037 - acc: 0.7926\n",
      "Epoch 52/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5037 - acc: 0.7926\n",
      "Epoch 53/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5036 - acc: 0.7926\n",
      "Epoch 54/150\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.5037 - acc: 0.7926\n",
      "Epoch 55/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5036 - acc: 0.7926\n",
      "Epoch 56/150\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.5036 - acc: 0.7926\n",
      "Epoch 57/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5036 - acc: 0.7926\n",
      "Epoch 58/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5035 - acc: 0.7926\n",
      "Epoch 59/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5035 - acc: 0.7926\n",
      "Epoch 60/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5035 - acc: 0.7926\n",
      "Epoch 61/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5035 - acc: 0.7926\n",
      "Epoch 62/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5035 - acc: 0.7926\n",
      "Epoch 63/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 64/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 65/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 66/150\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 67/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 68/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 69/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5034 - acc: 0.7926\n",
      "Epoch 70/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 71/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 72/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 73/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 74/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 75/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5033 - acc: 0.7926\n",
      "Epoch 76/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 77/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 78/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 79/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 80/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 81/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 82/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 84/150\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 85/150\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 86/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 87/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 88/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5032 - acc: 0.7926\n",
      "Epoch 89/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 90/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 91/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 92/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 93/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 94/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 95/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 96/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 97/150\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 98/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 99/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 100/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 101/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 102/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5031 - acc: 0.7926\n",
      "Epoch 103/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 104/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 105/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 106/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 107/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 108/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 109/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 110/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 111/150\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 112/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 113/150\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 114/150\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 115/150\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 116/150\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.5030 - acc: 0.7926\n",
      "Epoch 117/150\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 118/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 119/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 120/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 121/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 122/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 123/150\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 124/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 125/150\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 126/150\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 127/150\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 128/150\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 129/150\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 130/150\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 131/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 132/150\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 133/150\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 134/150\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 135/150\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 136/150\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 137/150\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 138/150\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 139/150\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 140/150\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 141/150\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 142/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 143/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 144/150\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 145/150\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 146/150\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 147/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5029 - acc: 0.7926\n",
      "Epoch 148/150\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 149/150\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.5028 - acc: 0.7926\n",
      "Epoch 150/150\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.5028 - acc: 0.7926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abb2bd7d68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=(13), activation='relu'))\n",
    "model.add(Dense(25,activation='relu'))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(training_normalized, Y_train, epochs=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 79.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 1s 199us/step - loss: 0.5344 - acc: 0.7671\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 1s 92us/step - loss: 0.5109 - acc: 0.7926: 0s - loss: 0.5009 - \n",
      "Epoch 3/50\n",
      "7000/7000 [==============================] - 1s 89us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 1s 91us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 1s 92us/step - loss: 0.5110 - acc: 0.7926\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 1s 89us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 1s 89us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 1s 89us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 1s 91us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 0.5110 - acc: 0.7926\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5110 - acc: 0.7926\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.5108 - acc: 0.7926\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.5107 - acc: 0.7926\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.5109 - acc: 0.7926\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.5110 - acc: 0.7926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abb4f5c588>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=13, activation='sigmoid'))\n",
    "model.add(Dense(25,activation='sigmoid'))\n",
    "model.add(Dense(20,activation='sigmoid'))\n",
    "model.add(Dense(15,activation='sigmoid'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(training_normalized, Y_train, epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change observed even with Optimization. We can see that the \n",
    "accuracy stays at 79.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the StandardScaler to standarize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_tr = sc.fit_transform(X_train,)\n",
    "X_te = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.4008 - acc: 0.8319\n",
      "Epoch 2/75\n",
      "7000/7000 [==============================] - 1s 209us/step - loss: 0.3495 - acc: 0.8569\n",
      "Epoch 3/75\n",
      "7000/7000 [==============================] - 2s 225us/step - loss: 0.3415 - acc: 0.8584\n",
      "Epoch 4/75\n",
      "7000/7000 [==============================] - 2s 221us/step - loss: 0.3373 - acc: 0.8611\n",
      "Epoch 5/75\n",
      "7000/7000 [==============================] - 1s 214us/step - loss: 0.3297 - acc: 0.8647\n",
      "Epoch 6/75\n",
      "7000/7000 [==============================] - 2s 217us/step - loss: 0.3258 - acc: 0.8664\n",
      "Epoch 7/75\n",
      "7000/7000 [==============================] - 2s 216us/step - loss: 0.3242 - acc: 0.8659\n",
      "Epoch 8/75\n",
      "7000/7000 [==============================] - 2s 235us/step - loss: 0.3207 - acc: 0.8691\n",
      "Epoch 9/75\n",
      "7000/7000 [==============================] - 2s 233us/step - loss: 0.3146 - acc: 0.8729\n",
      "Epoch 10/75\n",
      "7000/7000 [==============================] - 2s 225us/step - loss: 0.3118 - acc: 0.8741\n",
      "Epoch 11/75\n",
      "7000/7000 [==============================] - 1s 212us/step - loss: 0.3086 - acc: 0.8714\n",
      "Epoch 12/75\n",
      "7000/7000 [==============================] - 2s 226us/step - loss: 0.3026 - acc: 0.8773\n",
      "Epoch 13/75\n",
      "7000/7000 [==============================] - 2s 225us/step - loss: 0.2980 - acc: 0.8809\n",
      "Epoch 14/75\n",
      "7000/7000 [==============================] - 2s 228us/step - loss: 0.2953 - acc: 0.8761\n",
      "Epoch 15/75\n",
      "7000/7000 [==============================] - 2s 226us/step - loss: 0.2877 - acc: 0.8824\n",
      "Epoch 16/75\n",
      "7000/7000 [==============================] - 2s 230us/step - loss: 0.2856 - acc: 0.8854\n",
      "Epoch 17/75\n",
      "7000/7000 [==============================] - 2s 224us/step - loss: 0.2803 - acc: 0.8860\n",
      "Epoch 18/75\n",
      "7000/7000 [==============================] - 2s 215us/step - loss: 0.2758 - acc: 0.8883\n",
      "Epoch 19/75\n",
      "7000/7000 [==============================] - 1s 211us/step - loss: 0.2716 - acc: 0.8881\n",
      "Epoch 20/75\n",
      "7000/7000 [==============================] - 1s 211us/step - loss: 0.2633 - acc: 0.8914\n",
      "Epoch 21/75\n",
      "7000/7000 [==============================] - 1s 204us/step - loss: 0.2605 - acc: 0.8927\n",
      "Epoch 22/75\n",
      "7000/7000 [==============================] - 2s 224us/step - loss: 0.2545 - acc: 0.8959\n",
      "Epoch 23/75\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.2481 - acc: 0.8993\n",
      "Epoch 24/75\n",
      "7000/7000 [==============================] - 2s 252us/step - loss: 0.2447 - acc: 0.8981\n",
      "Epoch 25/75\n",
      "7000/7000 [==============================] - 2s 258us/step - loss: 0.2362 - acc: 0.8989\n",
      "Epoch 26/75\n",
      "7000/7000 [==============================] - 2s 274us/step - loss: 0.2375 - acc: 0.8993\n",
      "Epoch 27/75\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.2251 - acc: 0.9077\n",
      "Epoch 28/75\n",
      "7000/7000 [==============================] - 2s 272us/step - loss: 0.2212 - acc: 0.9083\n",
      "Epoch 29/75\n",
      "7000/7000 [==============================] - 2s 275us/step - loss: 0.2199 - acc: 0.9070\n",
      "Epoch 30/75\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 0.2146 - acc: 0.9114\n",
      "Epoch 31/75\n",
      "7000/7000 [==============================] - 2s 269us/step - loss: 0.2065 - acc: 0.9117\n",
      "Epoch 32/75\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.2044 - acc: 0.9159\n",
      "Epoch 33/75\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.2003 - acc: 0.913 - 2s 262us/step - loss: 0.2000 - acc: 0.9137\n",
      "Epoch 34/75\n",
      "7000/7000 [==============================] - 2s 274us/step - loss: 0.1951 - acc: 0.9181\n",
      "Epoch 35/75\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.1908 - acc: 0.9183\n",
      "Epoch 36/75\n",
      "7000/7000 [==============================] - 2s 275us/step - loss: 0.1878 - acc: 0.9194\n",
      "Epoch 37/75\n",
      "7000/7000 [==============================] - 2s 289us/step - loss: 0.1834 - acc: 0.9229\n",
      "Epoch 38/75\n",
      "7000/7000 [==============================] - 2s 284us/step - loss: 0.1801 - acc: 0.9229\n",
      "Epoch 39/75\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.1743 - acc: 0.9257\n",
      "Epoch 40/75\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.1688 - acc: 0.9281\n",
      "Epoch 41/75\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 0.1703 - acc: 0.9241\n",
      "Epoch 42/75\n",
      "7000/7000 [==============================] - 2s 285us/step - loss: 0.1624 - acc: 0.9304\n",
      "Epoch 43/75\n",
      "7000/7000 [==============================] - 2s 286us/step - loss: 0.1563 - acc: 0.9340\n",
      "Epoch 44/75\n",
      "7000/7000 [==============================] - 2s 249us/step - loss: 0.1562 - acc: 0.9327\n",
      "Epoch 45/75\n",
      "7000/7000 [==============================] - 2s 223us/step - loss: 0.1531 - acc: 0.9311\n",
      "Epoch 46/75\n",
      "7000/7000 [==============================] - 2s 234us/step - loss: 0.1533 - acc: 0.9323\n",
      "Epoch 47/75\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.1503 - acc: 0.9346\n",
      "Epoch 48/75\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.1410 - acc: 0.9354\n",
      "Epoch 49/75\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.1371 - acc: 0.9401\n",
      "Epoch 50/75\n",
      "7000/7000 [==============================] - 2s 215us/step - loss: 0.1394 - acc: 0.9407\n",
      "Epoch 51/75\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 0.1382 - acc: 0.9447\n",
      "Epoch 52/75\n",
      "7000/7000 [==============================] - 1s 188us/step - loss: 0.1291 - acc: 0.9443\n",
      "Epoch 53/75\n",
      "7000/7000 [==============================] - 1s 203us/step - loss: 0.1335 - acc: 0.9453\n",
      "Epoch 54/75\n",
      "7000/7000 [==============================] - 1s 198us/step - loss: 0.1199 - acc: 0.9466\n",
      "Epoch 55/75\n",
      "7000/7000 [==============================] - 2s 215us/step - loss: 0.1236 - acc: 0.9454\n",
      "Epoch 56/75\n",
      "7000/7000 [==============================] - 2s 215us/step - loss: 0.1213 - acc: 0.9460\n",
      "Epoch 57/75\n",
      "7000/7000 [==============================] - 2s 252us/step - loss: 0.1224 - acc: 0.9514\n",
      "Epoch 58/75\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 0.1150 - acc: 0.9523\n",
      "Epoch 59/75\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.1159 - acc: 0.9516\n",
      "Epoch 60/75\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.1068 - acc: 0.9534\n",
      "Epoch 61/75\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.1066 - acc: 0.9563\n",
      "Epoch 62/75\n",
      "7000/7000 [==============================] - 1s 179us/step - loss: 0.1038 - acc: 0.9561\n",
      "Epoch 63/75\n",
      "7000/7000 [==============================] - 1s 195us/step - loss: 0.1017 - acc: 0.9576\n",
      "Epoch 64/75\n",
      "7000/7000 [==============================] - 1s 198us/step - loss: 0.1016 - acc: 0.9559\n",
      "Epoch 65/75\n",
      "7000/7000 [==============================] - 1s 197us/step - loss: 0.0946 - acc: 0.9589\n",
      "Epoch 66/75\n",
      "7000/7000 [==============================] - 1s 200us/step - loss: 0.0999 - acc: 0.9587 1s -\n",
      "Epoch 67/75\n",
      "7000/7000 [==============================] - 1s 195us/step - loss: 0.0981 - acc: 0.9591\n",
      "Epoch 68/75\n",
      "7000/7000 [==============================] - 1s 192us/step - loss: 0.0912 - acc: 0.9621\n",
      "Epoch 69/75\n",
      "7000/7000 [==============================] - 1s 194us/step - loss: 0.0871 - acc: 0.9647\n",
      "Epoch 70/75\n",
      "7000/7000 [==============================] - 1s 190us/step - loss: 0.0857 - acc: 0.9639\n",
      "Epoch 71/75\n",
      "7000/7000 [==============================] - 2s 266us/step - loss: 0.1133 - acc: 0.9556\n",
      "Epoch 72/75\n",
      "7000/7000 [==============================] - 2s 276us/step - loss: 0.0977 - acc: 0.9619\n",
      "Epoch 73/75\n",
      "7000/7000 [==============================] - 2s 230us/step - loss: 0.0772 - acc: 0.9686\n",
      "Epoch 74/75\n",
      "7000/7000 [==============================] - 1s 179us/step - loss: 0.0804 - acc: 0.9664\n",
      "Epoch 75/75\n",
      "7000/7000 [==============================] - 1s 194us/step - loss: 0.0803 - acc: 0.9666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abc07fec18>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(150, input_dim=(13), activation='relu'))\n",
    "model2.add(Dense(75,activation='relu'))\n",
    "model2.add(Dense(25,activation='relu'))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_tr, y_train, epochs=75, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing the data, we see that we get good accuracy\n",
    "of 96.6%. We can use this model on our test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the results using 0.5 as a threshold (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02720937],\n",
       "       [0.9369291 ],\n",
       "       [0.05188015],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.7895621 ],\n",
       "       [0.84895325]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tr = []\n",
    "threshold = 0.5\n",
    "x = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > threshold:\n",
    "        x=1\n",
    "    else:\n",
    "        x=0\n",
    "    Y_pred_tr.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,Y_pred_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Model is 0.8236666666666667\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the Model is',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2187  228]\n",
      " [ 301  284]]\n"
     ]
    }
   ],
   "source": [
    "Cf = confusion_matrix(y_test,Y_pred_tr)\n",
    "print(Cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      2415\n",
      "           1       0.55      0.49      0.52       585\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3000\n",
      "   macro avg       0.72      0.70      0.70      3000\n",
      "weighted avg       0.82      0.82      0.82      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_te,Y_pred_tr)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post hyper paramenter tuning with 3 hidden layers we get the best\n",
    "performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
